{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73662a49-4073-4fd5-acfa-5dccc432815b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Datetime  Temperature   Humidity  WindSpeed  \\\n",
      "0  2020-01-01 00:00:00    11.829344  30.880622  30.360938   \n",
      "1  2020-01-01 01:00:00    29.154886  38.133578   7.481179   \n",
      "2  2020-01-01 02:00:00    23.362978  57.679549  17.435908   \n",
      "3  2020-01-01 03:00:00    31.083194  83.469354  13.093886   \n",
      "4  2020-01-01 04:00:00    25.229984  32.815848   7.667718   \n",
      "\n",
      "   GeneralDiffuseFlows  DiffuseFlows  PowerConsumption_Zone1  \\\n",
      "0           328.591293    399.367633             5720.378957   \n",
      "1           230.901116    542.826966             5583.450918   \n",
      "2           404.239627    220.301485             8288.914924   \n",
      "3           180.456382    274.905705             6614.632861   \n",
      "4            90.626333    450.753111             2190.434571   \n",
      "\n",
      "   PowerConsumption_Zone2  PowerConsumption_Zone3  \n",
      "0             7604.581893             8777.217575  \n",
      "1             5033.148829             9196.579473  \n",
      "2             8152.540637             5980.977412  \n",
      "3             4121.746930             8621.504285  \n",
      "4             8599.807386             2999.300401  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3478/3145409277.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  datetimes = pd.date_range(start=\"2020-01-01\", periods=num_rows, freq=\"H\").astype(str)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate random dataset\n",
    "def generate_test_dataset(num_rows: int) -> pd.DataFrame:\n",
    "    # Generate a range of datetimes\n",
    "    datetimes = pd.date_range(start=\"2020-01-01\", periods=num_rows, freq=\"H\").astype(str)\n",
    "    \n",
    "    data = {\n",
    "        \"Datetime\": datetimes,\n",
    "        \"Temperature\": np.random.uniform(-20, 40, num_rows),\n",
    "        \"Humidity\": np.random.uniform(0, 100, num_rows),\n",
    "        \"WindSpeed\": np.random.uniform(0, 32, num_rows),\n",
    "        \"GeneralDiffuseFlows\": np.random.uniform(0, 1000, num_rows),\n",
    "        \"DiffuseFlows\": np.random.uniform(0, 1000, num_rows),\n",
    "        \"PowerConsumption_Zone1\": np.random.uniform(0, 10000, num_rows),\n",
    "        \"PowerConsumption_Zone2\": np.random.uniform(0, 10000, num_rows),\n",
    "        \"PowerConsumption_Zone3\": np.random.uniform(0, 10000, num_rows)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate a sample dataset\n",
    "random_dataset = generate_test_dataset(100)  # Generate 100 rows of data\n",
    "print(random_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63b3ec3-ea5d-4831-ade9-1a4359ecc024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ray_env/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "2024-06-28 15:29:58,113\tINFO worker.py:1586 -- Connecting to existing Ray cluster at address: 10.0.1.209:6379...\n",
      "2024-06-28 15:29:58,139\tINFO worker.py:1762 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m10.0.1.209:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import ray \n",
    "\n",
    "ds = ray.data.from_pandas(random_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fe049de-434e-4104-b91d-7d49510355bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 15:35:51,059\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-06-28_13-39-03_152976_1135/logs/ray-data\n",
      "2024-06-28 15:35:51,059\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(BatchTransformer.transform)->MapBatches(drop_columns)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ba8dffabf84a97bf60e61d6103ab38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(BatchTransformer.transform)->MapBatches(drop_columns) 1:   0%|             | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcea997275224405817f5a6189367942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|                                                                        | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 15:35:51,131\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-06-28_13-39-03_152976_1135/logs/ray-data\n",
      "2024-06-28 15:35:51,132\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(BatchTransformer.transform)->MapBatches(drop_columns)->MapBatches(encode_categorical_columns)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df94fc5adec47de93b59df011809e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(BatchTransformer.transform)->MapBatches(drop_columns)->MapBatches(encode_categorical_columns) 1: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1917dad8b249c2bcd80096126daf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|                                                                        | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 15:35:51,280\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-06-28_13-39-03_152976_1135/logs/ray-data\n",
      "2024-06-28 15:35:51,281\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(BatchTransformer.transform)->MapBatches(drop_columns)->MapBatches(encode_categorical_columns)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333b1e8157944f4fa80f1eff5c56708d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(BatchTransformer.transform)->MapBatches(drop_columns)->MapBatches(encode_categorical_columns) 1: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e53853759b24505a009f4a5f3962afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|                                                                        | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# COMPUTING NEW FEATURES\n",
    "import pandas as pd\n",
    "\n",
    "class BatchTransformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def categorize_time_of_day(hour):\n",
    "        if 6 <= hour < 12:\n",
    "            return 'Morning'\n",
    "        elif 12 <= hour < 18:\n",
    "            return 'Afternoon'\n",
    "        elif 18 <= hour < 24:\n",
    "            return 'Evening'\n",
    "        else:\n",
    "            return 'Night'\n",
    "\n",
    "    @staticmethod\n",
    "    def categorize_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Autumn'\n",
    "\n",
    "    def transform(self, batch):\n",
    "        batch['Datetime'] = pd.to_datetime(batch['Datetime'])\n",
    "        batch['Year'] = batch['Datetime'].dt.year\n",
    "        batch['Month'] = batch['Datetime'].dt.month\n",
    "        batch['Day'] = batch['Datetime'].dt.day\n",
    "        batch['Hour'] = batch['Datetime'].dt.hour\n",
    "        batch['TimeOfDay'] = batch['Hour'].apply(self.categorize_time_of_day)\n",
    "        batch['Weekday'] = batch['Datetime'].dt.weekday\n",
    "        batch['IsWeekend'] = batch['Weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "        batch['Season'] = batch['Month'].apply(self.categorize_season)\n",
    "        batch['Year'] = batch['Year'].astype(int)\n",
    "        batch['Weekday'] = batch['Weekday'].astype(int)\n",
    "        batch['IsWeekend'] = batch['IsWeekend'].astype(int)\n",
    "        return batch\n",
    "\n",
    "# Instantiate the transformer\n",
    "transformer = BatchTransformer()\n",
    "\n",
    "# Assuming `ds` is your Ray dataset\n",
    "transformed_ds = ds.map_batches(transformer.transform, batch_format=\"pandas\")\n",
    "\n",
    "# _________________________________________________________\n",
    "# REMOVING UNNECESSARY COLUMNS\n",
    "ds_updated = transformed_ds.drop_columns([\"Datetime\"])\n",
    "\n",
    "df_updated = ds_updated.to_pandas()\n",
    "# df_updated.head()\n",
    "\n",
    "\n",
    "\n",
    "# _________________________________________________________\n",
    "# ENCODING THE CATEGORICAL COLUMNS\n",
    "import ray\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'ds' is your Ray dataset\n",
    "\n",
    "# Define the function to apply one-hot encoding\n",
    "def encode_categorical_columns(batch):\n",
    "    # Specify the columns you want to encode\n",
    "    categorical_columns = ['TimeOfDay', 'Season']\n",
    "    \n",
    "    # Apply one-hot encoding to the specified columns\n",
    "    batch_encoded = pd.get_dummies(batch, columns=categorical_columns)\n",
    "    \n",
    "    # Convert the resulting DataFrame to integer type\n",
    "    batch_encoded = batch_encoded.astype(int)\n",
    "    \n",
    "    return batch_encoded\n",
    "\n",
    "# Apply the function to each batch of the dataset\n",
    "ds_encoded = ds_updated.map_batches(encode_categorical_columns, batch_format=\"pandas\")\n",
    "\n",
    "# Convert the iterable returned by iter_batches to an iterator\n",
    "batches_iterator = iter(ds_encoded.iter_batches(batch_size=6, batch_format=\"pandas\"))\n",
    "\n",
    "# Now you can use next() to get the first batch\n",
    "first_batch = next(batches_iterator)\n",
    "\n",
    "# Display the first batch\n",
    "# print(first_batch)\n",
    "\n",
    "\n",
    "\n",
    "# _________________________________________________________\n",
    "df_encoded = ds_encoded.to_pandas()\n",
    "# df_encoded\n",
    "\n",
    "# import modin.pandas as pd\n",
    "\n",
    "# # Assuming df_encoded is loaded in a way that it's a Modin DataFrame\n",
    "\n",
    "# # Define aggregation functions\n",
    "# aggregation_functions = {\n",
    "#     'Temperature': ['mean'],\n",
    "#     'Humidity': ['mean'],\n",
    "#     'WindSpeed': ['mean'],\n",
    "#     'GeneralDiffuseFlows': ['mean'],\n",
    "#     'DiffuseFlows': ['mean'],\n",
    "#     'PowerConsumption_Zone1': ['sum'],\n",
    "#     'PowerConsumption_Zone2': ['sum'],\n",
    "#     'PowerConsumption_Zone3': ['sum'],\n",
    "#     # 'IsHoliday': ['first'],\n",
    "#     'Weekday': ['first'],\n",
    "#     'IsWeekend': ['first'],\n",
    "#     'TimeOfDay_Afternoon': ['first'],\n",
    "#     'TimeOfDay_Evening': ['first'],\n",
    "#     'TimeOfDay_Morning': ['first'],\n",
    "#     'TimeOfDay_Night': ['first'],\n",
    "#     'Season_Autumn': ['first'],\n",
    "#     'Season_Spring': ['first'],\n",
    "#     'Season_Summer': ['first'],\n",
    "#     'Season_Winter': ['first']\n",
    "# }\n",
    "\n",
    "# # Group by Year, Month, Day, Hour and aggregate\n",
    "# df_grouped = df_encoded.groupby(['Year', 'Month', 'Day', 'Hour']).agg(aggregation_functions)\n",
    "\n",
    "# # Correct column names\n",
    "# df_grouped.columns = ['_'.join(col) if isinstance(col, tuple) else col for col in df_grouped.columns]\n",
    "# df_grouped = df_grouped.reset_index()\n",
    "\n",
    "# # Display the result\n",
    "# # df_grouped.head(25)\n",
    "\n",
    "\n",
    "# # _________________________________________________________\n",
    "# # LAGGING THE COLUMNS\n",
    "\n",
    "# import modin.pandas as pd\n",
    "\n",
    "# # Assuming df_grouped is loaded or converted to a Modin DataFrame\n",
    "\n",
    "# # Columns to create lag features\n",
    "# columns_to_lag = [\n",
    "#     'Temperature_mean', 'Humidity_mean', 'WindSpeed_mean', 'GeneralDiffuseFlows_mean', \n",
    "#     'DiffuseFlows_mean', 'PowerConsumption_Zone1_sum', 'PowerConsumption_Zone2_sum', \n",
    "#     'PowerConsumption_Zone3_sum'\n",
    "# ]\n",
    "\n",
    "# # Lag values (24, 48, 72 hours)\n",
    "# lags = [4, 8, 12, 24, 48]\n",
    "\n",
    "# # Create lag features as before\n",
    "# df_lagged = df_grouped.copy()\n",
    "\n",
    "# for col in columns_to_lag:\n",
    "#     for lag in lags:\n",
    "#         df_lagged[f'{col}_lag{lag}'] = df_grouped[col].shift(lag)\n",
    "\n",
    "# # Replace NaN values with 0\n",
    "# df_lagged.fillna(0, inplace=True)\n",
    "\n",
    "# # Display the result\n",
    "# # df_lagged.head()\n",
    "\n",
    "\n",
    "\n",
    "# # _________________________________________________________\n",
    "# # FEATURE SCALING\n",
    "\n",
    "# # List of columns to scale\n",
    "# cols_to_scale = [\n",
    "#     \"Temperature_mean\", \"Humidity_mean\", \"WindSpeed_mean\", \n",
    "#     \"GeneralDiffuseFlows_mean\", \"DiffuseFlows_mean\", \"PowerConsumption_Zone1_sum\", \"PowerConsumption_Zone2_sum\", \"PowerConsumption_Zone3_sum\", \n",
    "#     \"Temperature_mean_lag4\", \"Temperature_mean_lag8\", \"Temperature_mean_lag12\", \"Temperature_mean_lag24\", \"Temperature_mean_lag48\", \n",
    "#     \"Humidity_mean_lag4\", \"Humidity_mean_lag8\", \"Humidity_mean_lag12\", \"Humidity_mean_lag24\", \"Humidity_mean_lag48\",\n",
    "#     \"WindSpeed_mean_lag4\", \"WindSpeed_mean_lag8\", \"WindSpeed_mean_lag12\", \"WindSpeed_mean_lag24\", \"WindSpeed_mean_lag48\", \n",
    "#     \"GeneralDiffuseFlows_mean_lag4\", \"GeneralDiffuseFlows_mean_lag8\", \"GeneralDiffuseFlows_mean_lag12\", \"GeneralDiffuseFlows_mean_lag24\", \"GeneralDiffuseFlows_mean_lag48\",\n",
    "#     \"DiffuseFlows_mean_lag4\", \"DiffuseFlows_mean_lag8\", \"DiffuseFlows_mean_lag12\", \"DiffuseFlows_mean_lag24\", \"DiffuseFlows_mean_lag48\", \n",
    "#     \"PowerConsumption_Zone1_sum_lag4\", \"PowerConsumption_Zone1_sum_lag8\", \"PowerConsumption_Zone1_sum_lag12\", \"PowerConsumption_Zone1_sum_lag24\", \"PowerConsumption_Zone1_sum_lag48\",\n",
    "#     \"PowerConsumption_Zone2_sum_lag4\", \"PowerConsumption_Zone2_sum_lag8\", \"PowerConsumption_Zone2_sum_lag12\", \"PowerConsumption_Zone2_sum_lag24\", \"PowerConsumption_Zone2_sum_lag48\", \n",
    "#     \"PowerConsumption_Zone3_sum_lag4\", \"PowerConsumption_Zone3_sum_lag8\", \"PowerConsumption_Zone3_sum_lag12\", \"PowerConsumption_Zone3_sum_lag24\",  \"PowerConsumption_Zone3_sum_lag48\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Convert the DataFrame to a Ray Dataset\n",
    "# ds = ray.data.from_pandas(df_lagged)\n",
    "\n",
    "# # Define a function to apply MinMaxScaler to a pandas DataFrame\n",
    "# def scale_partition(df, cols_to_scale):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
    "#     return df\n",
    "\n",
    "# # Use Ray's map_batches to apply the scaling function across partitions\n",
    "# # map_batches expects a function that operates on pandas DataFrames (or Arrow tables)\n",
    "# scaled_ds = feature_ds.map_batches(lambda batch: scale_partition(batch, cols_to_scale), batch_format=\"pandas\")\n",
    "\n",
    "# # Optionally, convert the scaled Ray Dataset back to a pandas DataFrame\n",
    "# scaled_df = scaled_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57ddbb-7bc6-470a-b001-333c5b8a0173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ec99fc7-32e0-4214-a6ef-67fa294ac6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 15:38:10,309\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-06-28_13-39-03_152976_1135/logs/ray-data\n",
      "2024-06-28 15:38:10,311\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(BatchTransformer.transform)->MapBatches(drop_columns)->MapBatches(encode_categorical_columns)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488c2ac9fe934d778ff74c178a1f0357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(BatchTransformer.transform)->MapBatches(drop_columns)->MapBatches(encode_categorical_columns) 1: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5b4b664bc544d09190467d121d7986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|                                                                        | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 15:38:10,376\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-06-28_13-39-03_152976_1135/logs/ray-data\n",
      "2024-06-28 15:38:10,376\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(BatchTransformer.transform)->MapBatches(drop_columns)->MapBatches(encode_categorical_columns)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Temperature  Humidity  WindSpeed  GeneralDiffuseFlows  DiffuseFlows  \\\n",
      "0           11        30         30                  328           399   \n",
      "1           29        38          7                  230           542   \n",
      "2           23        57         17                  404           220   \n",
      "3           31        83         13                  180           274   \n",
      "4           25        32          7                   90           450   \n",
      "5           28        98         13                  185           479   \n",
      "\n",
      "   PowerConsumption_Zone1  PowerConsumption_Zone2  PowerConsumption_Zone3  \\\n",
      "0                    5720                    7604                    8777   \n",
      "1                    5583                    5033                    9196   \n",
      "2                    8288                    8152                    5980   \n",
      "3                    6614                    4121                    8621   \n",
      "4                    2190                    8599                    2999   \n",
      "5                    4640                    4648                    2882   \n",
      "\n",
      "   Year  Month  Day  Hour  Weekday  IsWeekend  TimeOfDay_Afternoon  \\\n",
      "0  2020      1    1     0        2          0                    0   \n",
      "1  2020      1    1     1        2          0                    0   \n",
      "2  2020      1    1     2        2          0                    0   \n",
      "3  2020      1    1     3        2          0                    0   \n",
      "4  2020      1    1     4        2          0                    0   \n",
      "5  2020      1    1     5        2          0                    0   \n",
      "\n",
      "   TimeOfDay_Evening  TimeOfDay_Morning  TimeOfDay_Night  Season_Winter  \n",
      "0                  0                  0                1              1  \n",
      "1                  0                  0                1              1  \n",
      "2                  0                  0                1              1  \n",
      "3                  0                  0                1              1  \n",
      "4                  0                  0                1              1  \n",
      "5                  0                  0                1              1  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e35bbfad60474e95d465c54375c7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(BatchTransformer.transform)->MapBatches(drop_columns)->MapBatches(encode_categorical_columns) 1: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319cff36326b47c091f363d45c2854e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|                                                                        | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>GeneralDiffuseFlows</th>\n",
       "      <th>DiffuseFlows</th>\n",
       "      <th>PowerConsumption_Zone1</th>\n",
       "      <th>PowerConsumption_Zone2</th>\n",
       "      <th>PowerConsumption_Zone3</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>TimeOfDay_Afternoon</th>\n",
       "      <th>TimeOfDay_Evening</th>\n",
       "      <th>TimeOfDay_Morning</th>\n",
       "      <th>TimeOfDay_Night</th>\n",
       "      <th>Season_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>328</td>\n",
       "      <td>399</td>\n",
       "      <td>5720</td>\n",
       "      <td>7604</td>\n",
       "      <td>8777</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>230</td>\n",
       "      <td>542</td>\n",
       "      <td>5583</td>\n",
       "      <td>5033</td>\n",
       "      <td>9196</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>57</td>\n",
       "      <td>17</td>\n",
       "      <td>404</td>\n",
       "      <td>220</td>\n",
       "      <td>8288</td>\n",
       "      <td>8152</td>\n",
       "      <td>5980</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "      <td>180</td>\n",
       "      <td>274</td>\n",
       "      <td>6614</td>\n",
       "      <td>4121</td>\n",
       "      <td>8621</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>450</td>\n",
       "      <td>2190</td>\n",
       "      <td>8599</td>\n",
       "      <td>2999</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  WindSpeed  GeneralDiffuseFlows  DiffuseFlows  \\\n",
       "0           11        30         30                  328           399   \n",
       "1           29        38          7                  230           542   \n",
       "2           23        57         17                  404           220   \n",
       "3           31        83         13                  180           274   \n",
       "4           25        32          7                   90           450   \n",
       "\n",
       "   PowerConsumption_Zone1  PowerConsumption_Zone2  PowerConsumption_Zone3  \\\n",
       "0                    5720                    7604                    8777   \n",
       "1                    5583                    5033                    9196   \n",
       "2                    8288                    8152                    5980   \n",
       "3                    6614                    4121                    8621   \n",
       "4                    2190                    8599                    2999   \n",
       "\n",
       "   Year  Month  Day  Hour  Weekday  IsWeekend  TimeOfDay_Afternoon  \\\n",
       "0  2020      1    1     0        2          0                    0   \n",
       "1  2020      1    1     1        2          0                    0   \n",
       "2  2020      1    1     2        2          0                    0   \n",
       "3  2020      1    1     3        2          0                    0   \n",
       "4  2020      1    1     4        2          0                    0   \n",
       "\n",
       "   TimeOfDay_Evening  TimeOfDay_Morning  TimeOfDay_Night  Season_Winter  \n",
       "0                  0                  0                1              1  \n",
       "1                  0                  0                1              1  \n",
       "2                  0                  0                1              1  \n",
       "3                  0                  0                1              1  \n",
       "4                  0                  0                1              1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'ds' is your Ray dataset\n",
    "\n",
    "# Define the function to apply one-hot encoding\n",
    "def encode_categorical_columns(batch):\n",
    "    # Specify the columns you want to encode\n",
    "    categorical_columns = ['TimeOfDay', 'Season']\n",
    "    \n",
    "    # Apply one-hot encoding to the specified columns\n",
    "    batch_encoded = pd.get_dummies(batch, columns=categorical_columns)\n",
    "    \n",
    "    # Convert the resulting DataFrame to integer type\n",
    "    batch_encoded = batch_encoded.astype(int)\n",
    "    \n",
    "    return batch_encoded\n",
    "\n",
    "# Apply the function to each batch of the dataset\n",
    "ds_encoded = ds_updated.map_batches(encode_categorical_columns, batch_format=\"pandas\")\n",
    "\n",
    "# Convert the iterable returned by iter_batches to an iterator\n",
    "batches_iterator = iter(ds_encoded.iter_batches(batch_size=6, batch_format=\"pandas\"))\n",
    "\n",
    "# Now you can use next() to get the first batch\n",
    "first_batch = next(batches_iterator)\n",
    "\n",
    "# Display the first batch\n",
    "print(first_batch)\n",
    "df_encoded = ds_encoded.to_pandas()\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caff797-f711-44e0-8bd1-546c641e1e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
